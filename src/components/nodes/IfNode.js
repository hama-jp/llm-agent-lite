import { createNodeDefinition } from './types.js';

/**
 * Ifæ¡ä»¶åˆ†å²ãƒãƒ¼ãƒ‰ã®å®Ÿè¡Œå‡¦ç†
 * @param {Object} node - ãƒãƒ¼ãƒ‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
 * @param {Object} inputs - å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
 * @param {Object} context - å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
 * @returns {Promise<string>} æ¡ä»¶çµæœã«åŸºã¥ãå…¥åŠ›å€¤
 */
async function executeIfNode(node, inputs, context) {
  const conditionType = node.data.conditionType || 'llm';
  let conditionResult = false;
  
  if (conditionType === 'llm') {
    const condition = node.data.condition || '';
    const inputValue = inputs.input || '';
    const prompt = `${condition}\n\nå…¥åŠ›: ${inputValue}\n\nä¸Šè¨˜ã®æ¡ä»¶ã«åŸºã¥ã„ã¦ã€å…¥åŠ›ãŒæ¡ä»¶ã‚’æº€ãŸã™ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚æº€ãŸã™å ´åˆã¯ã€Œtrueã€ã€æº€ãŸã•ãªã„å ´åˆã¯ã€Œfalseã€ã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚`;
    
    try {
      const model = node.data.model;
      const temperature = node.data.temperature;
      const provider = node.data.provider || 'openai';

      // llmServiceã‚’å‹•çš„ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
      const { default: llmService } = await import('../../services/llmService.js');
      
      const currentSettings = llmService.loadSettings();
      const nodeSpecificOptions = {
        provider,
        model,
        temperature,
        apiKey: currentSettings.apiKey,
        baseUrl: currentSettings.baseUrl,
        maxTokens: currentSettings.maxTokens
      };
      
      const response = await llmService.sendMessage(prompt, nodeSpecificOptions);
      conditionResult = response.toLowerCase().includes('true');
    } catch (error) {
      throw new Error(`æ¡ä»¶åˆ¤æ–­ã‚¨ãƒ©ãƒ¼: ${error.message}`);
    }
  } else {
    // å¤‰æ•°æ¯”è¼ƒãƒ­ã‚¸ãƒƒã‚¯
    const variable = node.data.variable || '';
    const operator = node.data.operator || '==';
    const value = node.data.value || '';
    const variableValue = context.variables[variable];
    
    switch (operator) {
      case '==': conditionResult = variableValue == value; break;
      case '!=': conditionResult = variableValue != value; break;
      case '>': conditionResult = Number(variableValue) > Number(value); break;
      case '<': conditionResult = Number(variableValue) < Number(value); break;
      case '>=': conditionResult = Number(variableValue) >= Number(value); break;
      case '<=': conditionResult = Number(variableValue) <= Number(value); break;
      default: conditionResult = false;
    }
  }

  const inputValue = inputs.input || '';
  context.addLog('info', `æ¡ä»¶åˆ†å²ã®çµæœ: ${conditionResult}`, node.id, { conditionResult, inputValue });
  
  return inputValue;
}

/**
 * Ifæ¡ä»¶åˆ†å²ãƒãƒ¼ãƒ‰ã®å®šç¾©
 * æ¡ä»¶ã«åŸºã¥ã„ã¦ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’åˆ†å²ã•ã›ã‚‹
 */
export const IfNode = createNodeDefinition(
  'Ifæ¡ä»¶åˆ†å²',
  'ğŸ”€',
  'pink',
  ['input'], // å…¥åŠ›ãƒãƒ¼ãƒˆ: input
  ['true', 'false'], // å‡ºåŠ›ãƒãƒ¼ãƒˆ: true, false
  {
    conditionType: 'llm',
    condition: 'å…¥åŠ›ãŒè‚¯å®šçš„ãªå†…å®¹ã‹ã©ã†ã‹åˆ¤æ–­ã—ã¦ãã ã•ã„',
    variable: '',
    operator: '==',
    value: '',
    model: 'gpt-5-nano',
    temperature: 0.7
  },
  executeIfNode, // å®Ÿè¡Œãƒ¡ã‚½ãƒƒãƒ‰
  {
    description: 'æ¡ä»¶ã«åŸºã¥ã„ã¦ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’åˆ†å²ã•ã›ã¾ã™ã€‚LLMåˆ¤å®šã¾ãŸã¯å¤‰æ•°æ¯”è¼ƒã«ã‚ˆã‚‹æ¡ä»¶è¨­å®šãŒå¯èƒ½ã€‚',
    category: 'control-flow'
  }
);

export default IfNode;